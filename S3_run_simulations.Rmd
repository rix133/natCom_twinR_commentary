---
title: 'Suplementary Material 3: Run Simulations on the Last Birth Omited Data'
author: "Richard Meitern"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if(!is.null(knitr::opts_knit$get("rmarkdown.pandoc.to"))){
 if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "docx"){
 knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
} 
}

options(digits = 9)
options(scipen = 9)
options(knitr.kable.NA="")
```

## Introduction

The aim of this document is to display the R code needed the reproduce the simulations for the PISH scenarios. The letters P, I, S & H are used to indicate which mechanisms were included in each simulation scenario:

  * P indicates that a twinning event affects parity progression.
  * I indicates that a twinning event influences the time between that birth and the next one.
  * S indicates that a motherâ€™s reproductive schedule affects both her likelihood of having twins and her total number of births, creating a link between these two factors.
  * H indicates that there is a connection between twinning propensity and intrinsic fertility due to maternal heterogeneity.
  
The scenario 0 does not include any of these mechanisms. This documents needs the twinR package to be installed to run.

**NB!** Some of the code e.g reading in the data is same as in S1.

```{r}
#cleanup memory
gcstuff <- gc(verbose=FALSE); rm(gcstuff);
```


```{r}
#get last birth adding function
source("./R/last_birth.R")

#simplified twinR summary tables 
source("./R/twinR_summary.R")

#fix twinR compute predictions to do prediction with no lambda  as well
source("./R/twinR_predictions.R")

#simple convenience functions
source("./R/utils.R")
```


```{r}
## Identify number of CPU cores available for parallel computing,
## note: using a large number may lead RAM to max out, so you may have to adjust
## that according to your infrastructure:
nb_cores <- min(c(20L, parallel::detectCores() - 1))

## Set option in spaMM:
spaMM::spaMM.options(nb_cores = nb_cores)
```


## Data Import Estonia

The Estonian dataset has been formatted to include the same columns as *the data_births_all* dataset from the **twinR** package. The only difference is that the columns *pop* and *monthly* are excluded as these are constant.

```{r}
#Import and preproccess Estonian Data

data_births_monthly_EE <- readRDS("./data/data_births_all_EE.rds")

#the twinR package expects population to be present
data_births_monthly_EE$pop <- "Estonia" 

## Expand the birth level data for the fit of statistical models:
data_births_monthly_EE <- twinR::expand_data(data_births_monthly_EE)

data_births_monthly_EE <- add_last_birth(data_births_monthly_EE)

data_births_monthly_EE_not_last <- data_births_monthly_EE[!data_births_monthly_EE$last,]

```



## Data Import 9 Other European Populations

```{r}
##Import and pre-proccess twinR package data

## Filter the raw data to only keep data with monthly resolution:
data_births_monthly <- twinR::filter_data(twinR::data_births_all) 

## Expand the birth level data for the fit of statistical models:
data_births_monthly <- twinR::expand_data(data_births_monthly) 

data_births_monthly <- add_last_birth(data_births_monthly)
data_births_monthly_not_last <- data_births_monthly[!data_births_monthly$last,]

```


## Running Simulations

```{r}
# import the function to do model fit and predictions
source("./R/fit_models.R")
```

The following is copied directly from twinR documentation and only the saving directories and
input data frames are changed.


```{r}
#------------------------------------------------------------------------------------------------
#-------------------------------- Goodness-of-fit tests -----------------------------------------
#------------------------------------------------------------------------------------------------

### IMPORTANT: while all the steps above should work no matter the operating system and whether
### you are using R within a GUI (e.g. RStudio) or not, the following step is very
### computationally intensive and has been tailored to be used on a Unix system (e.g. Linux) and
### directly within a terminal. It may work in RStudio, but this is not guaranteed, nor
### recommended. If you run this code using Windows, it should fallback to running the
### computation sequentially instead of in parallel across multiple CPU cores, which should work
### fine at the cost of requiring probably weeks of running time.

### Run scenarios one by one and save the output in a rda file:

library(twinR)
library(doSNOW)
nb_cores <- min(c(20L, parallel::detectCores() - 1)) ## only 20 since large memory footprint
timeout <- 24 * 60 * 60 # a Day 

baseSlopeDir <- "./exports/slopes_under_scenarios"
baseFitDir <- "./exports/fitted_models"

scenarios_to_do <- c("base_model", "P", "I", "S", "H",
                     "PI", "PS", "PH", "IS", "IH", "SH",
                     "PIS", "PIH", "PSH", "ISH", "PISH")
```


### TwinR data

```{r}
expName <- "_orig_nl"
slopeDir <- paste0(baseSlopeDir, expName)
fitDir <- paste0(baseFitDir, expName)

dir.create(slopeDir)
dir.create(fitDir)

data_births_monthly <- data_births_monthly_not_last

## fit all trios of models in parallel (for linux only, but easy to adjust for other OS):
pbmcapply::pbmclapply(scenarios_to_do, function(scenario) {
  fits <- fit_life_histories(scenario = scenario,
                             birth_level_data = data_births_monthly)
  save(fits, file = paste0(fitDir,"/fits_", scenario, "_obs.rda"), compress = "xz")

  rm(fits)
  }, mc.cores = min(c(length(scenarios_to_do), nb_cores)), mc.preschedule = FALSE)



for (scenario in scenarios_to_do) {

   load(file = paste0(fitDir,"/fits_", scenario, "_obs.rda"))

   slopes_under_scenario <- simulate_slopes_for_GOF(N_replicates_level1 = 200L,
                                                    N_replicates_level2 = 49L,
                                                    birth_level_data = data_births_monthly,
                                                    life_history_fits = fits,
                                                    scenario = scenario,
                                                    nb_cores = nb_cores,
                                                    timeout = timeout,
                                                    .log = TRUE, lapply_pkg = "pbmcapply",
                                                    verbose = list(fit = TRUE, simu = FALSE))
   rm(fits)
   name_obj <- paste0("slopes_under_", scenario)
   assign(name_obj, value = slopes_under_scenario)
   save(list = name_obj, file = paste0(slopeDir, name_obj, ".rda"))
   rm(list = name_obj) # remove the object behind the name!
   rm(slopes_under_scenario, scenario, name_obj) # remove the object directly
   gc_stuff <- gc(verbose = FALSE)
}



## Combine simulated slopes:

all_slopes <- combine_simulated_slopes(path_slopes = slopeDir)


## Figure 5:

fig5 <- draw_fig_5(all_slopes, width = 1)
fig5Fname <- paste0("./exports/fig5_", expName, ".")
ggplot2::ggsave(file = paste0(fig5Fname, "pdf"), width = 88, height = 70, units = "mm")
ggplot2::ggsave(file = paste0(fig5Fname, "png"), width = 88, height = 70, units = "mm")


## test scenarios (table S13):

tableS13 <- goodness_of_fit(all_slopes)

write.csv(tableS13, file = paste0(fig5Fname, "csv"))


## computing time (for gof analysis):

computing_time_analysis(all_slopes)

```


### Estonain Data

```{r}
expName <- "_EE_nl"
slopeDir <- paste0(baseSlopeDir, expName)
fitDir <- paste0(baseFitDir, expName)

dir.create(slopeDir)
dir.create(fitDir)

data_births_monthly <- data_births_monthly_EE_not_last

## fit all trios of models in parallel (for linux only, but easy to adjust for other OS):
pbmcapply::pbmclapply(scenarios_to_do, function(scenario) {
  fits <- fit_life_histories(scenario = scenario,
                             birth_level_data = data_births_monthly)
  save(fits, file = paste0(fitDir,"/fits_", scenario, "_obs.rda"), compress = "xz")

  rm(fits)
  }, mc.cores = min(c(length(scenarios_to_do), nb_cores)), mc.preschedule = FALSE)



for (scenario in scenarios_to_do) {

   load(file = paste0(fitDir,"/fits_", scenario, "_obs.rda"))

   slopes_under_scenario <- simulate_slopes_for_GOF(N_replicates_level1 = 200L,
                                                    N_replicates_level2 = 49L,
                                                    birth_level_data = data_births_monthly,
                                                    life_history_fits = fits,
                                                    scenario = scenario,
                                                    nb_cores = nb_cores,
                                                    timeout = timeout,
                                                    .log = TRUE, lapply_pkg = "pbmcapply",
                                                    verbose = list(fit = TRUE, simu = FALSE))
   rm(fits)
   name_obj <- paste0("slopes_under_", scenario)
   assign(name_obj, value = slopes_under_scenario)
   save(list = name_obj, file = paste0(slopeDir, name_obj, ".rda"))
   rm(list = name_obj) # remove the object behind the name!
   rm(slopes_under_scenario, scenario, name_obj) # remove the object directly
   gc_stuff <- gc(verbose = FALSE)
}



## Combine simulated slopes:

all_slopes <- combine_simulated_slopes(path_slopes = slopeDir)


## Figure 5:

fig5 <- draw_fig_5(all_slopes, width = 1)
fig5Fname <- paste0("./exports/fig5_", expName, ".")
ggplot2::ggsave(file = paste0(fig5Fname, "pdf"), width = 88, height = 70, units = "mm")
ggplot2::ggsave(file = paste0(fig5Fname, "png"), width = 88, height = 70, units = "mm")


## test scenarios (table S13):

tableS13 <- goodness_of_fit(all_slopes)

write.csv(tableS13, file = paste0(fig5Fname, "csv"))


## computing time (for gof analysis):

computing_time_analysis(all_slopes)

```




```{r}
#END
```

